{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example api"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from adelecv.api.logs import enable_logs\n",
    "from adelecv.api.data.segmentations import SegmentationDataset\n",
    "from logging import StreamHandler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "enable_logs(StreamHandler())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from adelecv.api.config import Settings\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# you can change the path to save logs and weights\n",
    "# Settings.update_tmp_path(Path('your_path'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from adelecv.api.config import Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('tmp/cb0cb0afd3f84fb6b0d8299532ad8759')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.TMP_PATH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from adelecv.api.data.segmentations.types import ImageMask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 200/200 [1.6s elapsed, 0s remaining, 125.9 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Split dataset train size: 140, valid size: 40, test size: 20\n",
      "INFO - Creating a dataset\n",
      "DEBUG - Dataset created with params, dataset dir: F:\\dataset\\ph2, classes: {0: 'background', 1: 'target'}, batch size: 16\n"
     ]
    }
   ],
   "source": [
    "segm_dataset = SegmentationDataset(\n",
    "    r'F:\\dataset\\ph2',\n",
    "    ImageMask, # аннотация для наследника\n",
    "    (256, 256),\n",
    "    (0.7, 0.2, 0.1),\n",
    "    16,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from adelecv.api.models.segmentations import  get_encoders, get_pretrained_weights, get_models, get_torch_optimizers, get_losses, get_optimize_scores\n",
    "from adelecv.api.optimize.segmentations import get_hp_optimizers\n",
    "# создать отдельный модуль для получения возможных параметров"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models:  ['Unet', 'UnetPlusPlus', 'MAnet', 'Linknet', 'FPN', 'PSPNet', 'DeepLabV3', 'DeepLabV3Plus', 'PAN']\n",
      "encoders:  ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_32x48d', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'inceptionresnetv2', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7', 'mobilenet_v2', 'xception', 'timm-efficientnet-b0', 'timm-efficientnet-b1', 'timm-efficientnet-b2', 'timm-efficientnet-b3', 'timm-efficientnet-b4', 'timm-efficientnet-b5', 'timm-efficientnet-b6', 'timm-efficientnet-b7', 'timm-efficientnet-b8', 'timm-efficientnet-l2', 'timm-tf_efficientnet_lite0', 'timm-tf_efficientnet_lite1', 'timm-tf_efficientnet_lite2', 'timm-tf_efficientnet_lite3', 'timm-tf_efficientnet_lite4', 'timm-resnest14d', 'timm-resnest26d', 'timm-resnest50d', 'timm-resnest101e', 'timm-resnest200e', 'timm-resnest269e', 'timm-resnest50d_4s2x40d', 'timm-resnest50d_1s4x24d', 'timm-res2net50_26w_4s', 'timm-res2net101_26w_4s', 'timm-res2net50_26w_6s', 'timm-res2net50_26w_8s', 'timm-res2net50_48w_2s', 'timm-res2net50_14w_8s', 'timm-res2next50', 'timm-regnetx_002', 'timm-regnetx_004', 'timm-regnetx_006', 'timm-regnetx_008', 'timm-regnetx_016', 'timm-regnetx_032', 'timm-regnetx_040', 'timm-regnetx_064', 'timm-regnetx_080', 'timm-regnetx_120', 'timm-regnetx_160', 'timm-regnetx_320', 'timm-regnety_002', 'timm-regnety_004', 'timm-regnety_006', 'timm-regnety_008', 'timm-regnety_016', 'timm-regnety_032', 'timm-regnety_040', 'timm-regnety_064', 'timm-regnety_080', 'timm-regnety_120', 'timm-regnety_160', 'timm-regnety_320', 'timm-skresnet18', 'timm-skresnet34', 'timm-skresnext50_32x4d', 'timm-mobilenetv3_large_075', 'timm-mobilenetv3_large_100', 'timm-mobilenetv3_large_minimal_100', 'timm-mobilenetv3_small_075', 'timm-mobilenetv3_small_100', 'timm-mobilenetv3_small_minimal_100', 'timm-gernet_s', 'timm-gernet_m', 'timm-gernet_l', 'mit_b0', 'mit_b1', 'mit_b2', 'mit_b3', 'mit_b4', 'mit_b5', 'mobileone_s0', 'mobileone_s1', 'mobileone_s2', 'mobileone_s3', 'mobileone_s4']\n",
      "pretrained_weights ['imagenet', 'None']\n",
      "optimizers ['AdamW', 'Adadelta', 'Adam', 'SGD', 'RAdam', 'NAdam', 'RMSprop', 'Adagrad']\n",
      "losses ['JaccardLoss', 'DiceLoss', 'FocalLoss', 'LovaszLoss', 'SoftBCEWithLogitsLoss', 'SoftCrossEntropyLoss', 'TverskyLoss', 'MCCLoss']\n",
      "hp optimizers ['RandomSampler', 'GridSampler', 'TPESampler', 'CmaEsSampler', 'NSGAIISampler', 'QMCSampler', 'MOTPESampler']\n",
      "optimize scores ['fbeta_score', 'f1_score', 'iou_score', 'accuracy', 'positive_predictive_value', 'sensitivity', 'loss']\n"
     ]
    }
   ],
   "source": [
    "print('models: ', get_models())\n",
    "print('encoders: ', get_encoders())\n",
    "print('pretrained_weights', get_pretrained_weights())\n",
    "print('optimizers', get_torch_optimizers())\n",
    "print('losses', get_losses())\n",
    "print('hp optimizers', get_hp_optimizers())\n",
    "print('optimize scores', get_optimize_scores())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from adelecv.api.optimize.segmentations import HyperParamsSegmentation\n",
    "from adelecv.api.optimize.segmentations import HPOptimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "params = HyperParamsSegmentation(\n",
    "    strategy='TPESampler',\n",
    "    architectures=['UnetPlusPlus'],\n",
    "    encoders=['mobilenet_v2'],\n",
    "    pretrained_weights=['imagenet'],\n",
    "    loss_fns=['JaccardLoss'],\n",
    "    optimizers=['AdamW', 'RMSprop'],\n",
    "    epoch_range=(5, 5),\n",
    "    lr_range=(0.001, 0.003),\n",
    "    optimize_score='loss',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Create hp optimizer with params: strategy: TPESampler num_trials: 1 num_classes: 2 device: cuda hps: {'strategy': 'TPESampler', 'architectures': ['UnetPlusPlus'], 'encoders': ['mobilenet_v2'], 'pretrained_weights': ['imagenet'], 'loss_fns': ['JaccardLoss'], 'optimizers': ['AdamW', 'RMSprop'], 'epoch_range': (5, 5), 'lr_range': (0.001, 0.003), 'optimize_score': 'loss'}\n"
     ]
    }
   ],
   "source": [
    "hp_optimizer = HPOptimizer(\n",
    "    hyper_params=params,\n",
    "    num_trials=1,\n",
    "    device='GPU',\n",
    "    dataset=segm_dataset\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from adelecv.api.config import Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "tensorboard_logs_path = Settings.TENSORBOARD_LOGS_PATH.as_posix()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'tmp/cb0cb0afd3f84fb6b0d8299532ad8759/tensorboard'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_logs_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'tmp/cb0cb0afd3f84fb6b0d8299532ad8759/tensorboard'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_logs_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-10919857392befa1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-10919857392befa1\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir $tensorboard_logs_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Train models started\n",
      "\u001B[32m[I 2023-02-28 20:12:23,795]\u001B[0m A new study created in memory with name: no-name-27ad1279-2653-4d1b-9e5b-422a70b86bd0\u001B[0m\n",
      "DEBUG - Create tensorboard logger, path: tmp/cb0cb0afd3f84fb6b0d8299532ad8759/tensorboard/0a8754a\n",
      "DEBUG - Dataset updated\n",
      "INFO - Model 0a8754a_UnetPlusPlus_mobilenet_v2_imagenet_AdamW_JaccardLoss_lr=0,002541036844019805 trained with test loss 0.1143430769443512\n",
      "DEBUG - Add predictions for model: 0a8754a_UnetPlusPlus_mobilenet_v2_imagenet_AdamW_JaccardLoss_lr=0,002541036844019805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 200 [11.3s elapsed, 17.3 samples/s]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Save weights model: 0a8754a_UnetPlusPlus_mobilenet_v2_imagenet_AdamW_JaccardLoss_lr=0,002541036844019805, path: tmp/cb0cb0afd3f84fb6b0d8299532ad8759/weights/0a8754a.pt\n",
      "\u001B[32m[I 2023-02-28 20:13:13,306]\u001B[0m Trial 0 finished with value: 0.10235309600830078 and parameters: {'optimizer': 'AdamW', 'architecture': 'UnetPlusPlus', 'encoders': 'mobilenet_v2', 'pretrained_weight': 'imagenet', 'lr': 0.002541036844019805, 'loss': 'JaccardLoss', 'num_epoch': 5}. Best is trial 0 with value: 0.10235309600830078.\u001B[0m\n",
      "INFO - Study statistics:\n",
      "INFO - Number of finished trials: 1\n",
      "INFO - Number of pruned trials: 0\n",
      "INFO - Number of complete trials: 1\n",
      "INFO - Best trial:\n",
      "INFO - Value: 0.10235309600830078\n",
      "INFO - Params: \n",
      "INFO - optimizer: AdamW\n",
      "INFO - architecture: UnetPlusPlus\n",
      "INFO - encoders: mobilenet_v2\n",
      "INFO - pretrained_weight: imagenet\n",
      "INFO - lr: 0.002541036844019805\n",
      "INFO - loss: JaccardLoss\n",
      "INFO - num_epoch: 5\n",
      "INFO - Train models is over\n"
     ]
    }
   ],
   "source": [
    "hp_optimizer.optimize()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "       _id                                               name  architecture  \\\n0  0a8754a  0a8754a_UnetPlusPlus_mobilenet_v2_imagenet_Ada...  UnetPlusPlus   \n\n        encoder pretrained_weight        lr optimizer      loss_fn  num_epoch  \\\n0  mobilenet_v2          imagenet  0.002541     AdamW  JaccardLoss          5   \n\n    loss  fbeta_score  f1_score  iou_score  accuracy  \\\n0  0.114        0.921     0.921      0.861     0.943   \n\n   positive_predictive_value  sensitivity  \n0                      0.931        0.926  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>name</th>\n      <th>architecture</th>\n      <th>encoder</th>\n      <th>pretrained_weight</th>\n      <th>lr</th>\n      <th>optimizer</th>\n      <th>loss_fn</th>\n      <th>num_epoch</th>\n      <th>loss</th>\n      <th>fbeta_score</th>\n      <th>f1_score</th>\n      <th>iou_score</th>\n      <th>accuracy</th>\n      <th>positive_predictive_value</th>\n      <th>sensitivity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0a8754a</td>\n      <td>0a8754a_UnetPlusPlus_mobilenet_v2_imagenet_Ada...</td>\n      <td>UnetPlusPlus</td>\n      <td>mobilenet_v2</td>\n      <td>imagenet</td>\n      <td>0.002541</td>\n      <td>AdamW</td>\n      <td>JaccardLoss</td>\n      <td>5</td>\n      <td>0.114</td>\n      <td>0.921</td>\n      <td>0.921</td>\n      <td>0.861</td>\n      <td>0.943</td>\n      <td>0.931</td>\n      <td>0.926</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_optimizer.stats_models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from adelecv.api.modification_models import ExportWeights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you can save the selected weights in a zip file (feature for ui)\n",
    "# ExportWeights().create_zip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import fiftyone as fo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x255cc6855d0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=True&subscription=5a05bc1c-e14b-4099-8220-2ca2dff9392c\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset:          ImageMask\nMedia type:       image\nNum samples:      200\nSelected samples: 0\nSelected labels:  0\nSession URL:      http://localhost:5151/"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.launch_app(segm_dataset.fo_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
